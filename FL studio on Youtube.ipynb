{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4488951",
   "metadata": {},
   "source": [
    "__FL Studio Tuturials on Youtube__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyAuzxscfTqg5ElsuRhMHQx9zJGZyVzDqpM' #API code Sam\n",
    "api_key = 'AIzaSyBiBM47drg5csNW-V-wOZjNN-Vl5rfHNPM' #API code Jeroen\n",
    "#API key logged under  /Users/jeroenm/.zshrc with nano ~/.zshrc.API_KEY\n",
    "import os\n",
    "\n",
    "api_key = 'AIzaSyB770EnyGnPvNtdIgvqVyZIsnBeinWuyzQ' #API code Quinten\n",
    "api_key = 'AIzaSyA0v2in7KbrgrmjyxTBOrGcLEDn5QJeKio' #API code Tayfun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ.get('~/.zshrc.API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey= api_key )\n",
    "print(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a71a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the default number of results, this should give 5\n",
    "request = youtube.search().list(\n",
    "            q='FL tutorial',\n",
    "            part='snippet',\n",
    "            type='video')\n",
    "print(type(request))\n",
    "response = request.execute()\n",
    "print('Total items: ' , len(response['items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1278f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to increase to max of 50\n",
    "request = youtube.search().list(q='FL tutorial',part='snippet',type='video',maxResults=50)\n",
    "print(type(request))\n",
    "response = request.execute()\n",
    "print('Total items: ' , len(response['items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a5a02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print only the titles of the results within the retrieval range of 50.\n",
    "request = youtube.search().list(q='FL tutorial',part='snippet',type='video',maxResults=50)\n",
    "response = request.execute()\n",
    "next_page = response['nextPageToken']\n",
    "print(next_page) # to get next page token\n",
    "for item in response['items']:\n",
    "    print(item['snippet']['title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72639c35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# counts results within the retrieval range of 50 per page times 6 pages (page 0,1,2,3,4,5).\n",
    "# with every page the output provides iteration number and the nextPageToken\n",
    "no_requests = 0\n",
    "max_requests = 5\n",
    "import time\n",
    "\n",
    "search_res = []\n",
    "\n",
    "while no_requests <= max_requests:\n",
    "    no_requests += 1\n",
    "    print('iteration number:' + str(no_requests))\n",
    "    if (no_requests==1): \n",
    "        request = youtube.search().list(q='FL tutorial',part='snippet',type='video',maxResults=50)\n",
    "    else: \n",
    "        request = youtube.search().list(q='FL tutorial',part='snippet',type='video',maxResults=50, pageToken = next_page)\n",
    "       \n",
    "    response = request.execute()\n",
    "    next_page = response['nextPageToken']\n",
    "    print(next_page)\n",
    "\n",
    "    for item in response['items']:\n",
    "        search_res.append(item['snippet'])\n",
    "    time.sleep(1)   # change to 2 later\n",
    "\n",
    "len(search_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80502aaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### makes a list of videoIDs of six pages (50*6)\n",
    "\n",
    "videoIDs = []\n",
    "\n",
    "for item in search_res:\n",
    "    videoIDs.append(item['thumbnails']['default']['url'][23:34])\n",
    "\n",
    "print(\"Found \" + str(len(videoIDs)) + \" video IDs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793940a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# might be deleted later, since it doesnt add anything. Only helps for visualization.\n",
    "search_res[0:2] # only 2 to have some overview, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232725dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- stats --- #\n",
    "cnt=0\n",
    "for vid in videoIDs:\n",
    "    cnt+=1\n",
    "    if (cnt==5): \n",
    "        break   # pas aan naar 300\n",
    "    stats = youtube.videos().list(part='statistics',id=vid)\n",
    "    print(stats.execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d63de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### response for stats \n",
    "response_stats = []\n",
    "\n",
    "for vid in videoIDs:\n",
    "    stats = youtube.videos().list(part='statistics',id=vid)\n",
    "    response_stats.append(stats.execute())\n",
    "    res_stats = {}\n",
    "    \n",
    "    for item in response_stats:\n",
    "        stats = item['items'][0]['statistics'] ### the script works per id\n",
    "        res_stats[item['items'][0]['id']] = stats\n",
    "\n",
    "res_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b6f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output stats to json file\n",
    "import json\n",
    "converted_to_string = json.dumps(res_stats)\n",
    "f = open('outputfile1.json', 'a', encoding='utf-8')\n",
    "f.write(converted_to_string + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fba301",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read json file for stats\n",
    "f = open('outputfile1.json', 'r', encoding='utf-8')\n",
    "content = f.readlines()\n",
    "for item in content:\n",
    "    jsonobj = json.loads(item)\n",
    "    print(jsonobj)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6437dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json df for stats\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_json(r'outputfile1.json', orient = 'index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e751200",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# keep\n",
    "# write df for stats to csv\n",
    "df.to_csv('video_statistics.csv', index_label ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ end of stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- snippets ---#\n",
    "cnt=0\n",
    "for vid in videoIDs:\n",
    "    cnt+=1\n",
    "    if (cnt==5): break\n",
    "    snippets = youtube.videos().list(part='snippet',id=vid)\n",
    "    print(snippets.execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### response for snippets\n",
    "response_snippets = []\n",
    "\n",
    "for item in videoIDs:\n",
    "    snippets = youtube.videos().list(part='snippet',id=item)\n",
    "    response_snippets.append(snippets.execute())\n",
    "    res_snippets = {}\n",
    "    \n",
    "    for item in response_snippets:\n",
    "        snippets = item['items'][0]['snippet'] ### the script works per id\n",
    "        res_snippets[item['items'][0]['id']] = snippets\n",
    "\n",
    "res_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output snippets to json file\n",
    "import json\n",
    "converted_to_string = json.dumps(res_snippets)\n",
    "f = open('snippet_output.json', 'a', encoding='utf-8')\n",
    "f.write(converted_to_string + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63c380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read json file for snippet\n",
    "f = open('snippet_output.json', 'r', encoding='utf-8')\n",
    "content = f.readlines()\n",
    "for item in content:\n",
    "    jsonobj = json.loads(item)\n",
    "    print(jsonobj)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa90fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read json df for snippet\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_json(r'snippet_output.json', orient = 'index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500b4b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# write df for snippet to csv\n",
    "df.to_csv('video_snippets.csv', index_label ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "            #------------------ back up codes   ------------------------#\n",
    "\n",
    "### writer to csv    - old csv writer\n",
    "\n",
    "import csv\n",
    "    \n",
    "with open(\"output.csv\", \"w\") as csv_file:\n",
    "    field_names = [\"id\"]\n",
    "    print(field_names)\n",
    "    # Get keys of dictonary for column naming \n",
    "    # next(iter()) gets first entry of dict\n",
    "    for key in res_stats[next(iter(res_stats))].keys():\n",
    "        field_names.append(key)\n",
    "    print(field_names)\n",
    "    \n",
    "    writer = csv.writer(csv_file, delimiter = \";\")\n",
    "    writer.writerow(field_names)\n",
    "    # Loop over the result dictionaries corresponding to the videoIDs we have retreived earlier\n",
    "    for videoID in res_stats:\n",
    "        row_content = [videoID]\n",
    "        # Put each value from the current dict entry in the row_content\n",
    "        [row_content.append(value) for value in list(res_stats[videoID].values())]\n",
    "        writer.writerow(row_content)\n",
    "    print('Printing completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a33e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
