{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4488951",
   "metadata": {},
   "source": [
    "# FL Studio Tuturials on Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4addbe76",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bfa4d3",
   "metadata": {},
   "source": [
    "To run this code, the pip package \"google-api-python-client\" is required\n",
    "If not installed, please uncomment and run the following line by removing the '#':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3767e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9bfa6e",
   "metadata": {},
   "source": [
    "#### Once installed, restart and clean the kernel and continue from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92c290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720aadc",
   "metadata": {},
   "source": [
    "#### Create an api_key and store this credential as a Environment Variable on your local device\n",
    "In this project, the variable is defined in Terminal as  \"YOUTUBE_API\". For more information, check [this page](https://tilburgsciencehub.com/building-blocks/store-and-document-your-data/store-data/environment-variables/) or [this instructional video](https://www.youtube.com/watch?v=5iWhQWVXosU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2c709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ[\"YOUTUBE_API\"]\n",
    "api_key = 'AIzaSyB770EnyGnPvNtdIgvqVyZIsnBeinWuyzQ' # weg halen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99ac420",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey= api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea47f2f8",
   "metadata": {},
   "source": [
    "#### Testing the systems\n",
    "The cells below will check whether the API functions. \n",
    "\n",
    "Within this document, each definition of a parameter, operation or function is explained within the cells. These definitions should be considered as the same throughout the project unless mentioned otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c22a71a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items:  5\n"
     ]
    }
   ],
   "source": [
    "# check the default number of results, this should give 5\n",
    "\n",
    "# .search = executes the search method \n",
    "# .list = retrieves a list of zero or more resources\n",
    "# q = query term\n",
    "# part = identifies group of properties that should be returned\n",
    "# type = type of resource\n",
    "# snippet = provides overview with information about the video such as titles, description, thumbnails and tags\n",
    "# .execute = executes the request\n",
    "\n",
    "request = youtube.search().list(\n",
    "            q='FL tutorial',\n",
    "            part='snippet',\n",
    "            type='video')\n",
    "response = request.execute()\n",
    "print('Total items: ' , len(response['items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1278f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items:  50\n"
     ]
    }
   ],
   "source": [
    "# check the maximum number of results, this should give 50\n",
    "\n",
    "# maxResults = specifies the number of items that should be returned with a maximum of 50\n",
    "\n",
    "request = youtube.search().list(q='FL tutorial',part='snippet',type='video',maxResults=50)\n",
    "response = request.execute()\n",
    "print('Total items: ' , len(response['items']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1527b5",
   "metadata": {},
   "source": [
    "If the two cells above gave you the outputs **5** and **50** respectfully, the API works correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5d82f",
   "metadata": {},
   "source": [
    "#### Gathering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4a6644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create function for data collection\n",
    "\n",
    "# \n",
    "#\n",
    "#\n",
    "# next_page = every page contains a nextPageToken and this is used to iterate over multiple pages\n",
    "\n",
    "\n",
    "def retrieve_data(no_requests, max_requests):\n",
    "    search_res = []\n",
    "    \n",
    "    while no_requests <= max_requests:\n",
    "        try:\n",
    "            no_requests += 1\n",
    "            # if no results have been gathered, then go find the first result\n",
    "            # else get the result from the next page\n",
    "            if (no_requests==1): \n",
    "                request = youtube.search().list(q='FL tutorial',part='snippet',type='video',maxResults=50)\n",
    "            else:\n",
    "                request = youtube.search().list(q='FL tutorial',part='snippet',type='video',maxResults=50, pageToken = next_page)\n",
    "\n",
    "            # capture response and set next page\n",
    "            response = request.execute()\n",
    "            next_page = response['nextPageToken']\n",
    "        except:    \n",
    "            # if no next page is found, then stop the script\n",
    "            break\n",
    "\n",
    "        # add an item to the search_res list and wait 2 seconds before continuing with next page\n",
    "        for item in response['items']:\n",
    "            search_res.append(item['snippet'])\n",
    "        time.sleep(2)\n",
    "        \n",
    "    return search_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80502aaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 video IDs!\n"
     ]
    }
   ],
   "source": [
    "# make a list of videoIDs\n",
    "\n",
    "# videoIDs = list of all video ids\n",
    "videoIDs = []\n",
    "search_res = retrieve_data(no_requests=0, max_requests=100)\n",
    "\n",
    "for item in search_res:\n",
    "    videoIDs.append(item['thumbnails']['default']['url'][23:34])\n",
    "\n",
    "print(\"Found \" + str(len(videoIDs)) + \" video IDs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d63de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- start of gathering statistics --- #\n",
    "\n",
    "# response_stats = response of API for the statistics \n",
    "# res_stats = result of statistics\n",
    "response_stats = []\n",
    "\n",
    "for vid in videoIDs:\n",
    "    stats = youtube.videos().list(part='statistics',id=vid)\n",
    "    response_stats.append(stats.execute())\n",
    "    res_stats = {}\n",
    "    \n",
    "    for item in response_stats:\n",
    "        stats = item['items'][0]['statistics']\n",
    "        res_stats[item['items'][0]['id']] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b6f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output stats to json file\n",
    "converted_to_string = json.dumps(res_stats)\n",
    "f = open('stats_output.json', 'w', encoding='utf-8')\n",
    "f.write(converted_to_string + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71fba301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read json file for stats\n",
    "f = open('stats_output.json', 'r', encoding='utf-8')\n",
    "content = f.readlines()\n",
    "for item in content:\n",
    "    jsonobj = json.loads(item)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dcea643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drops favoriteCount column, this is an old feature that does not longer exist on YouTube\n",
    "dfstats = pd.read_json(r'stats_output.json', orient = 'index')\n",
    "dfstats.drop(dfstats.columns[3],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5b67677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean stats columns by removing NaNs and converting to int\n",
    "\n",
    "cols_stats = ['viewCount', 'likeCount', 'dislikeCount', 'commentCount']\n",
    "\n",
    "dfstats[cols_stats] = dfstats[cols_stats].fillna(0)\n",
    "dfstats[cols_stats] = dfstats[cols_stats].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d93ca9ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creates ratio for likes vs dislikes and comments vs viewcount in percentages\n",
    "\n",
    "dfstats['likeRatio %'] = (dfstats['likeCount']/(dfstats['likeCount'] + dfstats['dislikeCount']))*100\n",
    "dfstats['likeRatio %'] = dfstats['likeRatio %'].apply(lambda x: '%.1f' % x)\n",
    "\n",
    "dfstats['commentRatio %'] = (dfstats['commentCount']/dfstats['viewCount'])*100\n",
    "\n",
    "dfstats['commentRatio %'] = dfstats['commentRatio %'].apply(lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d4bccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe of video statistics to csv file\n",
    "\n",
    "dfstats.to_csv('video_statistics.csv', index_label ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86e3acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- start of gathering snippets --- #\n",
    "\n",
    "# response_snippets = response of API for the snippets of videos \n",
    "# res_snippets = result of snippets\n",
    "response_snippets = []\n",
    "\n",
    "for item in videoIDs:\n",
    "    snippets = youtube.videos().list(part='snippet',id=item)\n",
    "    response_snippets.append(snippets.execute())\n",
    "    res_snippets = {}\n",
    "    \n",
    "    for item in response_snippets:\n",
    "        snippets = item['items'][0]['snippet'] \n",
    "        res_snippets[item['items'][0]['id']] = snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98cea0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output snippets to json file\n",
    "\n",
    "converted_to_string = json.dumps(res_snippets)\n",
    "f = open('snippet_output.json', 'w', encoding='utf-8')\n",
    "f.write(converted_to_string + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1be6994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read json file for snippet\n",
    "f = open('snippet_output.json', 'r', encoding='utf-8')\n",
    "content = f.readlines()\n",
    "for item in content:\n",
    "    jsonobj = json.loads(item)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6ba23fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops column liveBroadcastContent which contains only the value \"none\"\n",
    "dfsnip = pd.read_json(r'snippet_output.json', orient = 'index')\n",
    "dfsnip.drop(dfsnip.columns[8],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dd622f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe of video snippets to csv file\n",
    "\n",
    "dfsnip.to_csv('video_snippets.csv', index_label ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f37a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- creation of Channel ID list ---#\n",
    "ChannelIDs = []\n",
    "\n",
    "for item in search_res:\n",
    "    ChannelIDs.append(item['channelId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1d31152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Response channel\n",
    "\n",
    "response_channel = []\n",
    "res_channels = {}\n",
    "for chn in ChannelIDs:\n",
    "    channel = youtube.channels().list(part='statistics',id=chn)\n",
    "    response_channel.append(channel.execute())\n",
    "    \n",
    "    for chn in response_channel:\n",
    "        channelstat = chn['items'][0]['statistics']\n",
    "        res_channels[chn['items'][0]['id']] = channelstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd1caac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output channel to json file\n",
    "\n",
    "converted_to_string = json.dumps(res_channels)\n",
    "f = open('channels_output.json', 'w', encoding='utf-8')\n",
    "f.write(converted_to_string + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca598b10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read json file for channel\n",
    "f = open('channels_output.json', 'r', encoding='utf-8')\n",
    "content = f.readlines()\n",
    "for item in content:\n",
    "    jsonobj = json.loads(item)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a995e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe of channel statistics to csv file\n",
    "\n",
    "dfchn = pd.read_json(r'channels_output.json', orient = 'index')\n",
    "dfchn.to_csv('video_channels.csv', index_label ='channelId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "911bbaa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--- merging the video snippets and statistics --- #\n",
    "dfsnip = pd.read_csv('video_snippets.csv')\n",
    "dfstats = pd.read_csv('video_statistics.csv')\n",
    "\n",
    "dfmerged = dfsnip.merge(dfstats, on='id')\n",
    "dfmerged.to_csv('video_output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
